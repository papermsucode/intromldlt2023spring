# Introduction to Machine and Deep Learning Theory

## Content
* [News](#news)
* [Short info](#info)
* [Time and place](#ww)
* [Communication with teachers](#feedback)
* [Task results](#marks)
* [Course program](#program)
* [Bibliography](#lit)
* [Useful links](#links)

## <a name="news" /> News
* The first lecture will take place on Wednesday 8, February, at 16:45 (online) 

## <a name="info" /> Short info 
In the spring semester of 2023 at the Faculty of Mechanics and Mathematics of Lomonosov Moscow State University a new special course of the student's choice, dedicated to the theory of machine learning and deep learning, is to be provided.

The course will be taught on the basis of the Department of [Mathematical Theory of Intelligent Systems](http://intsys.msu.ru/en/) under the guidance of Ph.D., Senior Researcher [Mazurenko I.L.](http://intsys.msu.ru/staff/mazurenko/) The course will be taught by Ph.D. [Petiushko A.A.](https://petiushko.info)

## <a name="ww" /> Time and place 
Classes are to be taught on Wednesdays at 16:45, online. 

## <a name="feedback" /> Communication with teachers
* [Telegram-channel](https://t.me/+OX_Ie45QTghjZmJi), where all important news will appear
* Feedback - by email papermsucode@gmail.com
* Well, you can always write in [issues](https://github.com/papermsucode/intromldlt2023spring/issues) :)

## <a name="marks" /> Task results
* [Summary table with results will be shared soon]()

## <a name="program" /> Course program
| Number        | Date          | Lecture                                            |
| ------------- | ------------- | -------------                                      |   
| 01            | 08.02.2023    | Empirical Risk and its Approximation. Loss Function. (Stochastic) Gradient Descent. MLE and MAP. Kullback-Leibler divergence and Cross Entropy | 

## <a name="lit" /> Bibliography
1. [Machine Learning Lecture Course](http://www.machinelearning.ru/wiki/index.php?title=Машинное_обучение_%28курс_лекций%2C_К.В.Воронцов%29) on http://www.machinelearning.ru from Vorontsov K.V.
2. Hastie, T. and Tibshirani, R. and Friedman, J. [The Elements of Statistical Learning](https://web.stanford.edu/~hastie/ElemStatLearn/printings/ESLII_print12.pdf), 2nd edition, Springer, 2009.
3. Bishop, C.M. [Pattern Recognition and Machine Learning](https://www.microsoft.com/en-us/research/uploads/prod/2006/01/Bishop-Pattern-Recognition-and-Machine-Learning-2006.pdf), Springer, 2006.
4. Ian Goodfellow, Yoshua Bengio, Aaron Courville, and Yoshua Bengio. Deep learning. Vol. 1. Cambridge: MIT press, 2016.
5. Matus Telgarsky, Deep learning theory lecture [notes](https://mjt.cs.illinois.edu/dlt/index.pdf), 2021
6. Sanjeev Arora et al., Theory of Deep learning book [draft](https://www.dropbox.com/s/smkp4vasbiszhw4/DLbook.pdf?dl=0), 2020

## <a name="links" /> Useful links 
### Introduction to machine learning
* Homemade Machine Learning: [github repo](https://github.com/trekhleb/homemade-machine-learning)
* Machine learning: [Course](https://www.coursera.org/learn/machine-learning) by Andrew Ng on the site https://www.coursera.org

### Theoretic Courses
* Foundations of Deep Learning: [Course](https://uclaml.github.io/CS269-Spring2021/) at UCLA
* Deep learning theory: [Course](https://mjt.cs.illinois.edu/dlt/) at UIUC
* Theoretical Deep Learning: [Course](https://www.cs.princeton.edu/courses/archive/fall19/cos597B/) at Princenton
